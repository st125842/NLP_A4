{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0a3470b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import re\n",
    "from   random import *\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import os   \n",
    "from tqdm import tqdm \n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76456384",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kiw00\\Documents\\work\\AIT\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "splits = {'test': 'plain_text/test-00000-of-00001.parquet', 'validation': 'plain_text/validation-00000-of-00001.parquet', 'train': 'plain_text/train-00000-of-00001.parquet'}\n",
    "df = pd.read_parquet(\"hf://datasets/stanfordnlp/snli/\" + splits[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6a9cf2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_parquet(\"hf://datasets/stanfordnlp/snli/\" + splits[\"train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b275591c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train[df_train['label'] != -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c28165a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.iloc[:100000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf0591d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r\"[.,!?\\\\-]\", '', text) # Remove punctuation\n",
    "    return text\n",
    "\n",
    "all_text = \" \".join([clean_text(row['premise']) + \" \" + clean_text(row['hypothesis']) for _, row in df_train.iterrows()])\n",
    "unique_words = set(all_text.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95b0d30a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Size: 17863\n"
     ]
    }
   ],
   "source": [
    "word2id = {'[PAD]': 0, '[CLS]': 1, '[SEP]': 2, '[UNK]': 3}\n",
    "for i, w in enumerate(unique_words):\n",
    "    word2id[w] = i + 4\n",
    "\n",
    "VOCAB_SIZE = len(word2id)\n",
    "print(f\"Vocabulary Size: {VOCAB_SIZE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2877e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SNLIDataset(Dataset):\n",
    "    def __init__(self, df, word2id, max_len):\n",
    "        self.df = df\n",
    "        self.word2id = word2id\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def tokenize(self, text):\n",
    "        tokens = clean_text(text).split()\n",
    "        ids = [self.word2id.get(w, self.word2id['[UNK]']) for w in tokens]\n",
    "        # Add [CLS] and [SEP]\n",
    "        ids = [self.word2id['[CLS]']] + ids + [self.word2id['[SEP]']]\n",
    "        # Pad or Truncate\n",
    "        if len(ids) < self.max_len:\n",
    "            ids = ids + [self.word2id['[PAD]']] * (self.max_len - len(ids))\n",
    "        else:\n",
    "            ids = ids[:self.max_len]\n",
    "        return torch.tensor(ids, dtype=torch.long)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        tokens_a = self.tokenize(row['premise'])\n",
    "        tokens_b = self.tokenize(row['hypothesis'])\n",
    "        label = torch.tensor(int(row['label']), dtype=torch.long)\n",
    "        return tokens_a, tokens_b, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e20bc636",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = SNLIDataset(df_train, word2id, 100)\n",
    "loader = DataLoader(dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "38b55900",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bert import BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "10de92b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_layers = 2    # number of Encoder of Encoder Layer\n",
    "n_heads  = 2    # number of heads in Multi-Head Attention\n",
    "d_model  = 256  # Embedding Size\n",
    "d_ff = 256 * 4  # 4*d_model, FeedForward dimension\n",
    "d_k = d_v = 16  # dimension of K(=Q), V\n",
    "n_segments = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ac4f0e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceBERT(nn.Module):\n",
    "    def __init__(self, bert_model, embed_dim, num_classes=3):\n",
    "        super(SentenceBERT, self).__init__()\n",
    "        self.bert = bert_model\n",
    "        \n",
    "        # The Classifier Layer: Takes concatenated (u, v, |u-v|)\n",
    "        # Input size is 3x the embedding dimension\n",
    "        self.classifier = nn.Linear(embed_dim * 3, num_classes)\n",
    "        self.device = bert_model.device\n",
    "\n",
    "    def mean_pooling(self, token_embeddings, attention_mask):\n",
    "        # token_embeddings shape: [batch_size, seq_len, embed_dim]\n",
    "        # attention_mask shape: [batch_size, seq_len]\n",
    "        \n",
    "        # Mask out padding tokens (make them zero so they don't affect average)\n",
    "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "        \n",
    "        # Sum of all valid token vectors\n",
    "        sum_embeddings = torch.sum(token_embeddings * input_mask_expanded, 1)\n",
    "        \n",
    "        # Count of valid tokens (avoid division by zero)\n",
    "        sum_mask = torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "        \n",
    "        # Average\n",
    "        return sum_embeddings / sum_mask\n",
    "\n",
    "    def forward(self, input_ids_a, input_ids_b):\n",
    "        # 1. Create dummy segment_ids (All zeros for single sentences)\n",
    "        # Your BERT expects segment_ids, but SBERT treats each sentence independently.\n",
    "        segment_ids_a = torch.zeros_like(input_ids_a).to(self.device)\n",
    "        segment_ids_b = torch.zeros_like(input_ids_b).to(self.device)\n",
    "\n",
    "        # 2. Pass through YOUR BERT (Shared Weights)\n",
    "        # We use get_last_hidden_state, NOT the forward() used for pre-training\n",
    "        out_a = self.bert.get_last_hidden_state(input_ids_a, segment_ids_a)\n",
    "        out_b = self.bert.get_last_hidden_state(input_ids_b, segment_ids_b)\n",
    "\n",
    "        # 3. Create Attention Masks (0 for PAD, 1 for Real)\n",
    "        # Assuming 0 is your PAD token ID\n",
    "        mask_a = (input_ids_a != 0) \n",
    "        mask_b = (input_ids_b != 0)\n",
    "\n",
    "        # 4. Mean Pooling -> u and v\n",
    "        u = self.mean_pooling(out_a, mask_a)\n",
    "        v = self.mean_pooling(out_b, mask_b)\n",
    "\n",
    "        # 5. Concatenate: (u, v, |u-v|)\n",
    "        features = torch.cat([u, v, torch.abs(u - v)], dim=1)\n",
    "\n",
    "        # 6. Classify\n",
    "        logits = self.classifier(features)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "14be64fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d9ef1cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_base_bert = BERT(n_layers, n_heads, d_model, d_ff, d_k, n_segments, VOCAB_SIZE, 100, device).to(device)\n",
    "# my_base_bert.load_state_dict(torch.load('bert_model.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1285e5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sbert_model = SentenceBERT(my_base_bert, embed_dim=d_model).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ed5f8c7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits: tensor([[-0.2589,  0.0661,  0.1251]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# 4. Test it with dummy data\n",
    "# Create two fake sentences of token IDs\n",
    "fake_a = torch.tensor([[1, 45, 23, 2, 0]]).to(device) # [CLS] ... [SEP] [PAD]\n",
    "fake_b = torch.tensor([[1, 99, 12, 2, 0]]).to(device)\n",
    "\n",
    "output = sbert_model(fake_a, fake_b)\n",
    "print(\"Logits:\", output) # Should be shape [1, 3] (Entailment, Neutral, Contradiction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5617fc61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, optimizer, criterion, epochs):\n",
    "    model.train()  # Set model to training mode\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        loop = tqdm(train_loader, leave=True)\n",
    "        total_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        for batch_idx, (input_ids_a, input_ids_b, labels) in enumerate(loop):\n",
    "            # Move data to GPU\n",
    "            input_ids_a = input_ids_a.to(device)\n",
    "            input_ids_b = input_ids_b.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # ---------------------------------------\n",
    "            # 1. Forward Pass\n",
    "            # ---------------------------------------\n",
    "            # The model takes two sentences (A & B) and outputs logits (3 classes)\n",
    "            outputs = model(input_ids_a, input_ids_b)\n",
    "\n",
    "            # ---------------------------------------\n",
    "            # 2. Calculate Loss\n",
    "            # ---------------------------------------\n",
    "            # print(outputs)\n",
    "            # print(labels)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # ---------------------------------------\n",
    "            # 3. Backward Pass (Optimization)\n",
    "            # ---------------------------------------\n",
    "            optimizer.zero_grad() # Clear old gradients\n",
    "            loss.backward()       # Calculate new gradients\n",
    "            optimizer.step()      # Update weights\n",
    "\n",
    "            # ---------------------------------------\n",
    "            # 4. Statistics\n",
    "            # ---------------------------------------\n",
    "            total_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "            # Update progress bar\n",
    "            loop.set_description(f\"Epoch [{epoch+1}/{epochs}]\")\n",
    "            loop.set_postfix(loss=loss.item(), acc=100*correct/total)\n",
    "\n",
    "    print(\"Training Complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "766ca291",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(sbert_model.parameters(), lr=1e-3)\n",
    "criterion = nn.CrossEntropyLoss() # For 3 classes (Entailment, Neutral, Contradiction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d9718d55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/20]: 100%|██████████| 3125/3125 [01:28<00:00, 35.31it/s, acc=58.7, loss=0.96] \n",
      "Epoch [2/20]: 100%|██████████| 3125/3125 [01:35<00:00, 32.57it/s, acc=66.4, loss=0.538]\n",
      "Epoch [3/20]: 100%|██████████| 3125/3125 [02:01<00:00, 25.65it/s, acc=69.4, loss=0.77] \n",
      "Epoch [4/20]: 100%|██████████| 3125/3125 [02:03<00:00, 25.22it/s, acc=71.7, loss=0.856]\n",
      "Epoch [5/20]: 100%|██████████| 3125/3125 [01:53<00:00, 27.59it/s, acc=73.4, loss=0.573]\n",
      "Epoch [6/20]: 100%|██████████| 3125/3125 [02:05<00:00, 24.98it/s, acc=74.9, loss=0.481]\n",
      "Epoch [7/20]: 100%|██████████| 3125/3125 [02:03<00:00, 25.39it/s, acc=76.3, loss=0.38] \n",
      "Epoch [8/20]: 100%|██████████| 3125/3125 [02:02<00:00, 25.51it/s, acc=77.7, loss=0.872]\n",
      "Epoch [9/20]: 100%|██████████| 3125/3125 [02:00<00:00, 26.03it/s, acc=78.9, loss=0.519]\n",
      "Epoch [10/20]: 100%|██████████| 3125/3125 [01:56<00:00, 26.78it/s, acc=80.1, loss=0.537]\n",
      "Epoch [11/20]: 100%|██████████| 3125/3125 [02:02<00:00, 25.49it/s, acc=81.4, loss=0.704]\n",
      "Epoch [12/20]: 100%|██████████| 3125/3125 [02:02<00:00, 25.60it/s, acc=82.5, loss=0.355]\n",
      "Epoch [13/20]: 100%|██████████| 3125/3125 [01:54<00:00, 27.35it/s, acc=83.8, loss=0.372] \n",
      "Epoch [14/20]: 100%|██████████| 3125/3125 [01:56<00:00, 26.89it/s, acc=85.2, loss=0.474]\n",
      "Epoch [15/20]: 100%|██████████| 3125/3125 [01:57<00:00, 26.62it/s, acc=86.2, loss=0.635] \n",
      "Epoch [16/20]: 100%|██████████| 3125/3125 [01:58<00:00, 26.39it/s, acc=87.5, loss=0.258] \n",
      "Epoch [17/20]: 100%|██████████| 3125/3125 [01:54<00:00, 27.41it/s, acc=88.6, loss=0.285] \n",
      "Epoch [18/20]: 100%|██████████| 3125/3125 [01:56<00:00, 26.74it/s, acc=89.8, loss=0.27]  \n",
      "Epoch [19/20]: 100%|██████████| 3125/3125 [01:57<00:00, 26.49it/s, acc=90.5, loss=0.197] \n",
      "Epoch [20/20]: 100%|██████████| 3125/3125 [01:58<00:00, 26.27it/s, acc=91.7, loss=0.113] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Complete!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_model(sbert_model, loader, optimizer, criterion, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b4706670",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(sbert_model.state_dict(), \"sbert_model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6752ef3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sbert_model.load_state_dict(torch.load('sbert_model.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6232b498",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_parquet(\"hf://datasets/stanfordnlp/snli/\" + splits[\"test\"])\n",
    "df_test = df_test[df_test['label'].isin([0, 1, 2])].dropna().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e00bdab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = SNLIDataset(df_test, word2id, 100)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "00a768a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "def evaluate_model(model, test_loader):\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    \n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    print(\"Evaluating...\")\n",
    "    with torch.no_grad():  # Disable gradient calculation for speed\n",
    "        for batch_a, batch_b, labels in tqdm(test_loader):\n",
    "            # Move to device\n",
    "            batch_a, batch_b, labels = batch_a.to(device), batch_b.to(device), labels.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(batch_a, batch_b)\n",
    "            \n",
    "            # Get predictions\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            \n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            \n",
    "    # Calculate Metrics\n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    print(f\"\\nTest Accuracy: {acc:.4f}\")\n",
    "    \n",
    "    # Detailed Report\n",
    "    target_names = ['Entailment', 'Neutral', 'Contradiction']\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(all_labels, all_preds, target_names=target_names))\n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1bfdc533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9824/9824 [01:11<00:00, 137.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Accuracy: 0.7051\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "   Entailment       0.73      0.74      0.74      3368\n",
      "      Neutral       0.64      0.68      0.66      3219\n",
      "Contradiction       0.74      0.69      0.72      3237\n",
      "\n",
      "     accuracy                           0.71      9824\n",
      "    macro avg       0.71      0.70      0.71      9824\n",
      " weighted avg       0.71      0.71      0.71      9824\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7051099348534202"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run evaluation\n",
    "evaluate_model(sbert_model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "946b62b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_inference(premise, hypothesis, model, dataset, device):\n",
    "    model.eval() # Set model to evaluation mode\n",
    "    \n",
    "    # 1. Tokenize using your specific method\n",
    "    # Your tokenizer returns shape [max_len], but model expects [batch_size, max_len]\n",
    "    # We use .unsqueeze(0) to add a batch size of 1\n",
    "    ids_a = dataset.tokenize(premise).unsqueeze(0).to(device)\n",
    "    ids_b = dataset.tokenize(hypothesis).unsqueeze(0).to(device)\n",
    "    \n",
    "    # 2. Forward Pass\n",
    "    with torch.no_grad():\n",
    "        logits = model(ids_a, ids_b)\n",
    "        probs = torch.softmax(logits, dim=1)\n",
    "        prediction = torch.argmax(probs, dim=1).item()\n",
    "        \n",
    "    # 3. Decode Result\n",
    "    label_map = {0: \"Entailment\", 1: \"Neutral\", 2: \"Contradiction\"}\n",
    "    confidence = probs[0][prediction].item()\n",
    "    \n",
    "    print(f\"\\nPremise:    {premise}\")\n",
    "    print(f\"Hypothesis: {hypothesis}\")\n",
    "    print(f\"Prediction: {label_map[prediction]} ({confidence*100:.2f}%)\")\n",
    "    \n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "156b85a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Premise:    A man is playing a guitar on stage\n",
      "Hypothesis: The man is performing music\n",
      "Prediction: Entailment (38.64%)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_inference(\n",
    "    premise=\"A man is playing a guitar on stage\", \n",
    "    hypothesis=\"The man is performing music\", \n",
    "    model=sbert_model, \n",
    "    dataset=dataset, # Uses your tokenizer logic\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725c7861",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AIT (3.10.18)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
